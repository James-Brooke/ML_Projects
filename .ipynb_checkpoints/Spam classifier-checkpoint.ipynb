{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sets available from http://spamassassin.apache.org/old/publiccorpus/\n",
    "\n",
    "Some of this code is adapted from https://github.com/ageron/handson-ml. I cannot recommend his book enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import email\n",
    "import email.policy\n",
    "import numpy as np\n",
    "import nltk\n",
    "import urlextract\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_path = \"D:\\Data_sets\\HamSpam\"\n",
    "files = [\"20030228_easy_ham.tar.bz2\",\"20030228_spam.tar.bz2\"]\n",
    "\n",
    "for file in files:\n",
    "    data_file = os.path.join(root_path,file)\n",
    "    tar_file = tarfile.open(data_file)\n",
    "    tar_file.extractall(path=root_path)\n",
    "    tar_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spamfiles = os.listdir(os.path.join(root_path,\"spam\"))\n",
    "hamfiles = os.listdir(os.path.join(root_path,\"easy_ham\"))\n",
    "\n",
    "spam_names = [filename for filename in spamfiles if len(filename) > 10] #The download comes with a misc file that is not an email\n",
    "easy_ham_names = [filename for filename in hamfiles if len(filename) >10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of HAM emails: 2500\n",
      "Number of SPAM emails: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of HAM emails: {}\".format(len(easy_ham_names)))\n",
    "print(\"Number of SPAM emails: {}\".format(len(spam_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_emails = []\n",
    "\n",
    "for filename in spam_names:\n",
    "    with open(os.path.join(root_path, \"spam\", filename), \"rb\") as f:\n",
    "        spam_emails.append(email.parser.BytesParser(policy=email.policy.default).parse(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me and my friends have this brand new idea, a Live Webcam\n",
      "<a href=\"http://%31%30%31%31%30%31%31%31%30%31%31%31%31%30%31%30%31%30%31%30%31%30%31%31%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%31%30%31%30%31%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%30%31%31%30%30%30%31%30%31%31%30%31%31%31%30%31%30%31%30%31%30%31%30%31%30%30%30%31%31%30%31%30%31%30%31%31%30%31%30%31%30%31%30%31%31%30%31@%34%2E%34%37%2E%39%36%2E%31%34%31/msga.html\">\n",
      " Click Here\n",
      " <a>\n",
      " </a>\n",
      " <br>\n",
      "  <br>\n",
      "   <br>\n",
      "    <font size=\"1\">\n",
      "     This is NOT SPAM - You have received this e-mail because \n",
      "at one time or another you entered the weekly draw at one of\n",
      "our portals or FFA sites. We comply with all proposed and current laws \n",
      "on commercial e-mail under (Bill s. 1618 TITLE III passed by the 105th \n",
      "Congress).\n",
      " If you have received this e-mail in error, we apologize for the \n",
      "inconvenience and ask that you remove yourself. \n",
      "Click\n",
      "     <a href=\"mailto:myscrotumhurts@aol.com\">\n",
      "      Here to Unsubscribe\n",
      "     </a>\n",
      "     <br>\n",
      "      fysibvcgjyuwinmyvbpjtaebsymyukbrkn\n",
      "     </br>\n",
      "    </font>\n",
      "   </br>\n",
      "  </br>\n",
      " </br>\n",
      "</a>\n"
     ]
    }
   ],
   "source": [
    "random_spam = spam_emails[201].get_content() \n",
    "soup = BeautifulSoup(random_spam, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ham_emails = []\n",
    "\n",
    "for filename in easy_ham_names:\n",
    "    with open(os.path.join(root_path, \"easy_ham\", filename), \"rb\") as f:\n",
    "        ham_emails.append(email.parser.BytesParser(policy=email.policy.default).parse(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inn Share's [shareinnn@yahoo.com] 22 lines of wisdom included:\n",
      "&gt; \n",
      "&gt; Hi,all:\n",
      "&gt; \n",
      "&gt; Does anyone know how to list the biggest file in my\n",
      "&gt; root directory?or the second biggest ..etc...\n",
      "&gt; \n",
      "&gt; Because I want to find out what is the reason cause my\n",
      "&gt; root all most full.\n",
      "\n",
      "$ find /dir -name \\*  | xargs du -s | sort -n\n",
      "\n",
      "Smallest files are listed first with the largest at the end. So if\n",
      "you want to get the 5 largest files, pipe through tail.\n",
      "\n",
      "e.g.\n",
      "\n",
      "$ find /dir -name \\*  | xargs du -s | sort -n | tail -5\n",
      "-- \n",
      "  Philip Reynolds        \n",
      "   RFC Networks          tel: 01 8832063\n",
      "www.rfc-networks.ie      fax: 01 8832041\n",
      "\n",
      "-- \n",
      "Irish Linux Users' Group: ilug@linux.ie\n",
      "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
      "List maintainer: listmaster@linux.ie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_ham = ham_emails[201].get_content() \n",
    "soup = BeautifulSoup(random_ham, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(ham_emails + spam_emails)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "\n",
    "    for part in email.walk():\n",
    "        \n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content() \n",
    "        except: \n",
    "            content = part.get_payload()\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        \n",
    "        else:\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            text =  soup.get_text().replace('\\n',' ')\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Inn Share's [shareinnn@yahoo.com] 22 lines of wisdom included:\\n> \\n> Hi,all:\\n> \\n> Does anyone know how to list the biggest file in my\\n> root directory?or the second biggest ..etc...\\n> \\n> Because I want to find out what is the reason cause my\\n> root all most full.\\n\\n$ find /dir -name \\\\*  | xargs du -s | sort -n\\n\\nSmallest files are listed first with the largest at the end. So if\\nyou want to get the 5 largest files, pipe through tail.\\n\\ne.g.\\n\\n$ find /dir -name \\\\*  | xargs du -s | sort -n | tail -5\\n-- \\n  Philip Reynolds        \\n   RFC Networks          tel: 01 8832063\\nwww.rfc-networks.ie      fax: 01 8832041\\n\\n-- \\nIrish Linux Users' Group: ilug@linux.ie\\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\nList maintainer: listmaster@linux.ie\\n\\n\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_to_text(ham_emails[201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Me and my friends have this brand new idea, a Live Webcam  Click Here     This is NOT SPAM - You have received this e-mail because  at one time or another you entered the weekly draw at one of our portals or FFA sites. We comply with all proposed and current laws  on commercial e-mail under (Bill s. 1618 TITLE III passed by the 105th  Congress).  If you have received this e-mail in error, we apologize for the  inconvenience and ask that you remove yourself.  Click  Here to Unsubscribe   fysibvcgjyuwinmyvbpjtaebsymyukbrkn  '"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_to_text(spam_emails[201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.UniformResourseLocaters.com']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_extractor = urlextract.URLExtract()\n",
    "url_extractor.find_urls('This pulls out www.UniformResourseLocaters.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.PorterStemmer() #e.g. \"fishing\" / \"fisher\" / \"fished\" --> \"fish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EmailWordCounter(BaseEstimator, TransformerMixin): #Compatible with sklearn \n",
    "           \n",
    "    def __init__(self, z=1):\n",
    "        self.z = z \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        X_transformed = []\n",
    "        \n",
    "        for email in X:\n",
    "            \n",
    "            text = email_to_text(email) #Extract email content text \n",
    "            \n",
    "            try:\n",
    "                text = text.lower() \n",
    "            except: \n",
    "                content = email.get_payload() #One email could not be parsed without this\n",
    "                soup = BeautifulSoup(content, 'html.parser')\n",
    "                text = soup.get_text().replace('\\n',' ').lower()\n",
    "            \n",
    "            urls = list(set(url_extractor.find_urls(text))) \n",
    "            urls.sort(key=lambda url: len(url), reverse=True)\n",
    "            for url in urls:\n",
    "                text = text.replace(url, \" URL \") # Replace URL's\n",
    "                    \n",
    "            text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text) # Replace numbers\n",
    "\n",
    "            text = re.sub(r'\\W+', ' ', text, flags=re.M) #Replace punctuation\n",
    "                \n",
    "            word_counts = Counter(text.split())\n",
    "            \n",
    "            stemmed_word_counts = Counter()\n",
    "                \n",
    "            for word, count in word_counts.items():\n",
    "                stemmed_word = stemmer.stem(word)\n",
    "                stemmed_word_counts[stemmed_word] += count\n",
    "            word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts) #Stem words\n",
    "            \n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ Counter({'dvd': 11, 'NUMBER': 9, 'a': 7, 'you': 7, 'and': 6, 'for': 4, 'or': 4, 'to': 4, 'be': 4, 'we': 4, 'your': 4, 'r': 3, 'ani': 3, 'burner': 3, 'list': 3, 'backup': 3, 'in': 3, 'thi': 3, 'offer': 3, 'as': 3, 'are': 3, 'our': 3, 'by': 2, 'cd': 2, 's': 2, 'limit': 2, 'do': 2, 'have': 2, 'vh': 2, 'unsubscrib': 2, 'if': 2, 'show': 2, 'of': 2, 'pro': 2, 'today': 2, 'how': 2, 'use': 2, 'cassett': 2, 'onli': 2, 'wizard': 2, 'from': 2, 'not': 2, 'spam': 2, 'here': 2, 'go': 2, 'order': 2, 'is': 2, 'opt': 2, 'packag': 2, 'copi': 2, 'email': 2, 'will': 2, 'further': 1, 'lose': 1, 'but': 1, 'inform': 1, 'mrsa': 1, 'previous': 1, 'well': 1, 'messag': 1, 'instant': 1, 'ever': 1, 'abus': 1, 'remov': 1, 'an': 1, 'now': 1, 'much': 1, 'receiv': 1, 'scratch': 1, 'method': 1, 'address': 1, 'shape': 1, 'complet': 1, 'avail': 1, 'about': 1, 'center': 1, 'code': 1, 'reproduct': 1, 'obtain': 1, 'won': 1, 'technolog': 1, 'creat': 1, 'press': 1, 'cooper': 1, 'may': 1, 'unlik': 1, 'click': 1, 'send': 1, 'most': 1, 'thank': 1, 'never': 1, 'person': 1, 'condon': 1, 'access': 1, 'control': 1, 'wish': 1, 'night': 1, 'fulli': 1, 'outdat': 1, 't': 1, 'other': 1, 'time': 1, 'competitor': 1, 'fool': 1, 'advanc': 1, 'veri': 1, 'disappoint': 1, 'it': 1, 'rw': 1, 'own': 1, 'librari': 1, 'purchas': 1, 'anyth': 1, 'form': 1, 'again': 1, 'guarante': 1, 'wa': 1, 'worri': 1, 'pleas': 1, 'fli': 1, 'make': 1, 'kindli': 1, 'timeonli': 1, 'still': 1, 'the': 1, 'sold': 1, 'qualiti': 1, 'with': 1, 'websit': 1}),\n",
       "       Counter({'thi': 4, 'you': 4, 'and': 3, 'have': 3, 'mail': 3, 'the': 3, 'e': 3, 'one': 2, 'at': 2, 'or': 2, 'here': 2, 'receiv': 2, 'click': 2, 'we': 2, 'brand': 1, 'pass': 1, 'me': 1, 'by': 1, 'ffa': 1, 'draw': 1, 'ofour': 1, 'bill': 1, 'live': 1, 'time': 1, 'a': 1, 'iii': 1, 'for': 1, 'becaus': 1, 'remov': 1, 'under': 1, 'not': 1, 'portal': 1, 'titl': 1, 'enter': 1, 'site': 1, 'weekli': 1, 'current': 1, 'spam': 1, 'apolog': 1, 'on': 1, 'anoth': 1, 'to': 1, 'compli': 1, 'NUMBERth': 1, 'error': 1, 'ask': 1, 'all': 1, 'inconveni': 1, 'if': 1, 'propos': 1, 'congress': 1, 'is': 1, 'law': 1, 's': 1, 'in': 1, 'yourself': 1, 'unsubscribefysibvcgjyuwinmyvbpjtaebsymyukbrkn': 1, 'my': 1, 'webcam': 1, 'with': 1, 'commerci': 1, 'new': 1, 'friend': 1, 'NUMBER': 1, 'that': 1, 'idea': 1})], dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmailWordCounter().fit_transform(spam_emails[200:202])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ Counter({'URL': 3, 'i': 3, 'waider': 2, 'that': 2, 'if': 2, 'in': 2, 'it': 2, 'person': 1, 're': 1, 'fact': 1, 'me': 1, 'cheer': 1, 'good': 1, 'she': 1, 'folk': 1, 'doom': 1, 'way': 1, 'borrow': 1, 's': 1, 'group': 1, 'inform': 1, 'beg': 1, 'doolin': 1, 'get': 1, 'a': 1, 'truli': 1, 'you': 1, 'm': 1, 'probabl': 1, 'of': 1, 'steal': 1, 'start': 1, 'your': 1, 'not': 1, 'beforeth': 1, 'now': 1, 'are': 1, 'or': 1, 'befor': 1, 'much': 1, 'far': 1, 'veri': 1, 'list': 1, 'zawinski': 1, 'lbw': 1, 'they': 1, 'depart': 1, 'irish': 1, 'user': 1, 'un': 1, 'ilug': 1, 'for': 1, 'can': 1, 'linux': 1, 'gone': 1, 'subscript': 1, 'well': 1, 'just': 1, 'maintain': 1, 'back': 1, 'too': 1, 'leav': 1, 'we': 1, 'say': 1, 'and': 1, 'jami': 1, 'realiz': 1, 'ye': 1, 'listmast': 1, 'head': 1, 'there': 1, 'fun': 1, 'is': 1}),\n",
       "       Counter({'the': 6, 'NUMBER': 6, 's': 3, 'to': 3, 'file': 3, 'URL': 3, 'list': 3, 'find': 3, 'biggest': 2, 'sort': 2, 'dir': 2, 'all': 2, 'my': 2, 'name': 2, 'largest': 2, 'root': 2, 'xarg': 2, 'tail': 2, 'want': 2, 'du': 2, 'caus': 1, 'inform': 1, 'fax': 1, 'com': 1, 'with': 1, 'first': 1, 'end': 1, 'know': 1, 'group': 1, 'irish': 1, 'through': 1, 'philip': 1, 'get': 1, 'how': 1, 'i': 1, 'un': 1, 'are': 1, 'inn': 1, 'shareinnn': 1, 'becaus': 1, 'reynold': 1, 'tel': 1, 'or': 1, 'ilug': 1, 'network': 1, 'hi': 1, 'e': 1, 'nsmallest': 1, 'etc': 1, 'rfc': 1, 'user': 1, 'g': 1, 'n': 1, 'full': 1, 'yahoo': 1, 'share': 1, 'linux': 1, 'wisdom': 1, 'subscript': 1, 'second': 1, 'of': 1, 'maintain': 1, 'at': 1, 'most': 1, 'reason': 1, 'pipe': 1, 'so': 1, 'what': 1, 'for': 1, 'line': 1, 'ifyou': 1, 'in': 1, 'listmast': 1, 'includ': 1, 'is': 1, 'out': 1, 'doe': 1, 'anyon': 1, 'directori': 1})], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmailWordCounter().fit_transform(ham_emails[200:202])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CounterToVector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        total_count = Counter()\n",
    "        \n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "                \n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common_ = most_common\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        \n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "                \n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"email_wordcounter\", EmailWordCounter()),\n",
    "    (\"counter_to_vector\", CounterToVector()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_transformed = pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 1001)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98584697651000897"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "score = cross_val_score(log_reg, X_train_transformed, y_train, cv=10)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "98.6% CV accuracy on the training set, not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_transformed = pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1001)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_transformed, y_train)\n",
    "\n",
    "predictions = log_reg.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85999999999999999"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much lower performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[507,  76],\n",
       "       [  8,   9]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10588235294117647"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81333333333333335"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = LinearSVC()\n",
    "SVM.fit(X_train_transformed, y_train)\n",
    "\n",
    "predictions = SVM.predict(X_test_transformed)\n",
    "\n",
    "np.mean(predictions==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[473,  70],\n",
       "       [ 42,  15]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM does not do much better, trading accuracy for a slight increase in precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7533333333333333"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = LinearSVC(class_weight='balanced') # Assign higher penalty to misclassifying SPAM \n",
    "SVM.fit(X_train_transformed, y_train)\n",
    "\n",
    "predictions = SVM.predict(X_test_transformed)\n",
    "\n",
    "np.mean(predictions==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[434,  67],\n",
       "       [ 81,  18]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dense = X_train_transformed.toarray() # Naive Bayes requires dense array\n",
    "X_test_dense = X_test_transformed.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67833333333333334"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train_dense, y_train)\n",
    "\n",
    "predictions = NB.predict(X_test_dense)\n",
    "\n",
    "np.mean(predictions==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[387,  65],\n",
       "       [128,  20]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes has the highest precision, but the lowest Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23529411764705882"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(predictions,y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
