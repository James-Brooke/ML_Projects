{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character level LSTM text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a statistical language model of the comments left on Reddit, in the Donald Trump subreddit. Using an LSTM neural network, it is possible to sample from the model to generate text that comes from a distribution designed to be similar to the distribution of text posted by reddit users. This is an attempt to simulate the average poster in The_Donald.   \n",
    "\n",
    "Some of this code is inspired by Francois Chollet's \"Deep learning with Python\", a book that I would certainly recommend. \n",
    "\n",
    "The data is the same as that in the \"The_Donald subreddit\" notebook, where I have linked its source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import random \n",
    "\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\Data_sets\\Reddit\\The_Donald_nov17.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filt1 = (data['selftext']!='[removed]')\n",
    "filt2 = (data['selftext']!='[deleted]')\n",
    "filt3 = (data['selftext'].notnull())\n",
    "\n",
    "data = data[filt1&filt2&filt3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "accepted = string.ascii_lowercase + \" \" + string.digits + \",!\\\"\\'#%():.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in data.itertuples():\n",
    "    \n",
    "    holder = []\n",
    "    \n",
    "    for i in getattr(row, \"selftext\").replace(\",\", \" comma\"):\n",
    "        if i.lower() in accepted:\n",
    "            holder.append(i)\n",
    "            \n",
    "    corpus.append(\"\".join(holder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = \" \".join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = corpus.replace(\" comma\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Think about it. Still the same race, but we'd be 'brown'. Their heads would explode. They constantly say we hate 'brown' people. How would that work https:www.youtube.comwatchvUhoU7lINYxkhe is so cool, really. Order 10 large pizzas and take it to your local police department. You helping to support Papa John's for leaving that stupid NFL crap and you're also helping to support the men and women in blue. Let's make this happen My thoughts, condolences and prayers to the victims and families of th\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 60\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(corpus) - maxlen, step):\n",
    "    sentences.append(corpus[i: i + maxlen])\n",
    "    next_chars.append(corpus[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162142"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_indices = dict((char, chars.index(char)) for char in chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=0.5):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(256, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1162142/1162142 [==============================] - 713s 613us/step - loss: 1.8965\n",
      "Epoch 1/1\n",
      "1162142/1162142 [==============================] - 718s 618us/step - loss: 1.7360\n",
      "\n",
      "Generating: \n",
      "\n",
      " ot share that a course that the part to she partus it and the low them was and immigred to the Many many of here and the gthe only that you tern of an out the more that my busk the continue shous the  \n",
      "\n",
      "Epoch 1/1\n",
      "1162142/1162142 [==============================] - 722s 621us/step - loss: 1.6978\n",
      "Epoch 1/1\n",
      "1162142/1162142 [==============================] - 714s 614us/step - loss: 1.6820\n",
      "\n",
      "Generating: \n",
      "\n",
      " teted in the truth. Also or and they are fact of the democrats set to actually be president that they sreat with a committee of in more and a the the new to be the middle has have to the most access.  \n",
      "\n",
      "Epoch 1/1\n",
      "1162142/1162142 [==============================] - 713s 613us/step - loss: 1.6749\n",
      "Epoch 1/1\n",
      "1162142/1162142 [==============================] - 713s 614us/step - loss: 1.6714\n",
      "\n",
      "Generating: \n",
      "\n",
      "  in the leaders can was a beguning and the probably from the stand or the support and be in the gopwatcher is a mental regarding the people. I can't not all and the program of the politician continues \n",
      "\n",
      "Epoch 1/1\n",
      "1162142/1162142 [==============================] - 713s 613us/step - loss: 1.6723\n",
      "Epoch 1/1\n",
      "1162142/1162142 [==============================] - 713s 613us/step - loss: 1.6783\n",
      "\n",
      "Generating: \n",
      "\n",
      " of the course of the still makes the most on the protest of the will he all the made of the sumers and shit with the will all the lendy is not a twitter law law of the time and all the day by the coun \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,31):\n",
    "    model.fit(x, y, batch_size=256, epochs=1)\n",
    "    if i % 5 == 0:\n",
    "        \n",
    "        start_index = random.randint(0, len(corpus) - maxlen - 1)\n",
    "        generated_text = corpus[start_index: start_index + maxlen]\n",
    "        \n",
    "        holder = []\n",
    "        \n",
    "        for i in range(300):\n",
    "            \n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1 \n",
    "                \n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds)\n",
    "            next_char = chars[next_index]\n",
    "            \n",
    "            holder.append(next_char)\n",
    "            \n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            \n",
    "        print(\"\\nGenerating: \\n\\n\", \"\".join(holder), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
